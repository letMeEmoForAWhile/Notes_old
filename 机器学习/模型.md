# 一、SVM（support Vector Mac）

- 支持向量机：二分类模型，在特征空间中寻求间隔最大的分离超平面。
- 主要思想：找到空间中的一个更够将所有数据样本划开的超平面，并且使得本集中所有数据到这个超平面的距离最短。

### 1、支持向量和超平面

先了解**线性分类器**的概念：设二维平面有两类不同的数据，分别用圆圈和方块表示。我们可以找到一条直线使得两类数据正好完全分开。图一中的三条直线都能满足条件，我们希望寻找到这样的直线，使得距离这条直线最近的点到这条直线的距离最大，L2就是这样的直线。从图2中直观来解释这一句话就是要求的两条外面的线之间的间隔最大。这是可以理解的，因为假如数据样本是随机出现的，那么这样分割之后数据点落入到其类别一侧的概率越高那么最终预测的准确率也会越高。在高维空间中这样的直线称之为**超平面**，因为当维数大于三的时候我们已经无法想象出这个平面的具体样子。那些距离这个超平面最近的点就是所谓**支持向量**，实际上如果确定了支持向量也就确定了这个超平面，找到这些支持向量之后其他样本就不会起作用了。

![image-20210723215612442](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210723215612442.png)

### 2 、SVM实现多类分类原理

##### 		2.1 、直接法

​		同时考虑所有分类，直接在目标函数上进行修改，将多个分类面的参数求解合并到一个最优化问题中，通过求解该最优化问题“一次性”实现多类分类。这种方法看似简单，但其计算复杂度比较高，实现起来比较困难，只适合用于小型问题中。

##### 		2.2、间接法

​		通过组合多个二分类器来实现多分类器的构造，常见的方法有one-against-one（one-versus-one）和one-against-all (one-versus-rest)两种。

​	**2.2.1一对多法（one-versus-rest,简称OVR SVMs）**

​	    训练时依次把某个类别的样本归为一类,其他剩余的样本归为另一类，这样k个类别的样本就构造出了k个SVM。分类时将未知样本分类为具有最大分类函数值的那类。

　假如我有四类要划分（也就是4个Label），他们是A、B、C、D。

　　于是我在抽取训练集的时候，分别抽取

　　（1）A所对应的向量作为**正集**，B，C，D所对应的向量作为负集；

　　（2）B所对应的向量作为**正集**，A，C，D所对应的向量作为负集；

　　（3）C所对应的向量作为**正集**，A，B，D所对应的向量作为负集；

　　（4）D所对应的向量作为**正集**，A，B，C所对应的向量作为负集；

　　使用这四个训练集分别进行训练，然后的得到四个训练结果文件。

　　在测试的时候，把对应的测试向量分别利用这四个训练结果文件进行测试。

　　最后每个测试都有一个结果f1(x),f2(x),f3(x),f4(x)。

　　于是最终的结果便是**这四个值中最大的**(因为one-versus-rest中的one是正集)一个作为分类结果

**2.2.2一对一法（one-versus-one,简称OVO SVMs或者pairwise）**

​		在任意两类样本之间设计一个SVM,因此k个类别的样本就需要设计k(k-1)/2个SVM

​		当对一个位置样本进行分类时，最后得票最多的类别即为该未知样本的类别。投票方法如下：

- A=B=C=D=0

- (A,B)-classifier, if A win, A=A+1;otherwise,B=B+1;

- (A,C)-classifier, if A win, A=A+1;otherwise,C=C+1;

  ……

- (C,D)-classifier, if C win, C=C+1;otherwise,D=D+1;

评价：

-  当类别很多的时候，model的个数时n(n-1)/2,代价相当大。
- 增加样本的时候，不需要重新训练所有的SVM，只需训练和增加样本相关的分类器

### 3、代码实现

利用sklearn中已经封装好的库

- 导入相关库

  ```
  from sklearn import svm
  ```

- 创建svm分类器

  ```
  model=svm.SVC(C=2,kernel='rbf',gamma=10,decision_function_shape='ovo') 
  model.fit(train_data,train_label.ravel()) #ravel函数在降维时默认是行序优先
  ```

  利用sklearn中的SVC（）创建分类器对象，其中常用的参数有C（惩罚力度）、kernel（核函数）、gamma（核函数的参数设置）、decision_function_shape（因变量的形式）

- 完整代码

  ```
  from sklearn import svm
  import numpy as np
  import matplotlib.pyplot as plt
  import matplotlib
  from sklearn.model_selection import train_test_split
  
  import joblib
  import pickle
  
  #定义字典，将字符与数字对应起来
  def Iris_label(s):
      it={b'Iris-setosa':0, b'Iris-versicolor':1, b'Iris-virginica':2}
      return it[s]
  
  
  #读取数据，利用np.loadtxt()读取text中的数据
  path='iris.data'             
  data= np.loadtxt(path, dtype=float, delimiter=',', converters={4:Iris_label}) #分隔符为‘,'
  
  
  #确定输入和输出
  x,y=np.split(data,(4,),axis=1)   #将data按前4列返回给x作为输入，最后1列给y作为标签值
  print("x\n",x)
  x=x[:,0:2]              #取x的前2列作为svm的输入，为了方便展示
  
  
  
  # 网络结构搭建
  
  train_data,test_data,train_label,test_label=train_test_split(x,y,random_state=1,train_size=0.6,test_size=0.4)
  
  print("train_label",train_label)
  model=svm.SVC(C=2,kernel='rbf',gamma=10,decision_function_shape='ovo') 
  model.fit(train_data,train_label.ravel())    #ravel函数在降维时默认是行序优先
  
  # 保存模型
  
  # joblib.dump(model, 'SVM_model.pkl')
  
  with open ('SVM_model.pickle', 'wb') as f:
      pickle.dump(model, f)    
  
  #读取模型
  
  # model1 = joblib.load('SVM_model.pkl') 
  
  with open ('SVM_model.pickle', 'rb') as f:
      model1 = pickle.load(f)    
  
  # 准确率
  
  train_score = model1.score(train_data,train_label)
  print("训练集：",train_score)
  test_score = model1.score(test_data,test_label)
  print("测试集：",test_score)
  
  print('train_decision_function:\n',model1.decision_function(train_data))#（90，3）
  
  #预测结果和展示
  
  #训练集和测试集的预测结果,reshape(-1,1)转换成一列，reshape（1，-1）转换成一行
  trainPredict = (model1.predict(train_data).reshape(-1, 1))
  testPredict = model1.predict(test_data).reshape(-1, 1)
  #将预测结果进行展示,首先画出预测点，再画出分类界面
  #预测点的画法，可参考https://zhuanlan.zhihu.com/p/81006952
  #画图例和点集
  x1_min,x1_max=x[:,0].min(),x[:,0].max()   #x轴范围  
  x2_min,x2_max=x[:,1].min(),x[:,1].max()   #y轴范围
  matplotlib.rcParams['font.sans-serif']=['SimHei']   #指定默认字体
  cm_dark=matplotlib.colors.ListedColormap(['g','r','b'])  #设置点集颜色格式  
  cm_light=matplotlib.colors.ListedColormap(['#A0FFA0','#FFA0A0','#A0A0FF'])  #设置边界颜色 
  plt.xlabel('花萼长度',fontsize=13)        #x轴标注
  plt.ylabel('花萼宽度',fontsize=13)        #y轴标注
  plt.xlim(x1_min,x1_max)                   #x轴范围
  plt.ylim(x2_min,x2_max)                   #y轴范围
  plt.title('鸢尾花SVM二特征分类')          #标题
  plt.scatter(x[:,0],x[:,1],c=y[:,0],s=30,cmap=cm_dark)  #画出测试点  
  plt.scatter(test_data[:,0],test_data[:,1],c=test_label[:,0],s=30,edgecolors='k',zorder=2,cmap=cm_dark) #画出预测点，并将预测点圈出 
  #画分类界面
  x1,x2=np.mgrid[x1_min:x1_max:200j,x2_min:x2_max:200j]#生成网络采样点  
  grid_test=np.stack((x1.flat,x2.flat),axis=1)#测试点
  grid_hat=model.predict(grid_test)# 预测分类值  
  grid_hat=grid_hat.reshape(x1.shape)# 使之与输入的形状相同
  plt.pcolormesh(x1,x2,grid_hat,cmap=cm_light)# 预测值的显示 
  plt.show() 
  ```
  

### 4、sklearn官方文档

##### SVC的参数

```
class sklearn.svm.SVC(*,  C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=- 1, decision_function_shape='ovr', break_ties=False, random_state=None)
```

fit time 至少和样本数量的四次方相关。对于样本数量巨大的数据，一般应该在Nystroem转换器之后使用LinearSVC或者SGDClassifier

- （重要）**C：正则化参数，默认值为1。**正则化的强度和C成反比。低的C值使分界面平滑，而高的C值通过增加模型自由度以选择更多支持向量来确保所有样本都被正确分类。

- （重要）**kernel：指定使用的核函数，默认为rbf**。值必须为以下之一：‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable.如果给定了callable ，则用于从数据矩阵中预计算内核矩阵：矩阵应该是一个形状矩阵（n_samples, n_samples）

- （重要）**degree：int，default =3**. Degree of the polynomial kernel function (‘poly’).Ignored by all other kernels.

- （重要）**gamma: {'scale','auto'} or float, default='scale'.** **‘rbf’,'poly'和’sigmoid‘**的内核系数。参数gamma定义了单个训练样本的影响大小，值越小影响越大，值越大影响越小。

  if `gamma='scale'` (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,

  if ‘auto’, uses 1 / n_features.

- （重要）**decision_function_shape:{'ovo',‘ovr’},default='ovr'**

  Whether to return a one-vs-rest (‘ovr’) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one (‘ovo’) is always used as multi-class strategy. The parameter is ignored for binary classification

##### SVC方法

- **decision_function**(X),为X中的样本评估decision_function

| Parameters：  | **X：array-like of shape (n_samples, n_features)**           |
| ------------- | ------------------------------------------------------------ |
| **Returns**： | **X：ndarray of shape (n_samples, n_classes \* (n_classes-1) / 2)**                                         如果decision_function_shape='ovr',则shape为（n_samples,n_calsses） |

- **fit**( X, y, sample_weight = None )

| Parameters    | **X**：{array-like, sparse matrix} of shape (n_samples, n_features) or (n_samples, n_samples)                         <br />Training vectors, where n_samples is the number of samples and n_features is the number of features. For kernel=”precomputed”, the expected shape of X is (n_samples, n_samples).                                                                                                                    **y**： array-like of shape (n_samples,)<br />Target values (class labels in classification, real numbers in regression).                                                                                                       **sample_weight**           <br /> |
| ------------- | ------------------------------------------------------------ |
| **Returns：** | self: object                                                 |

- get_params( deep = True)

- predict(X)

  预测X中样本的类别。

| Parameters:  | X:{array-like,sparse matrix} of shape (n_samples, n_features) or (n_samples_test, n_samples_train)<br />对于内核”precomputed“，期望的X形状为（x_samples_test, n_samples_train） |
| ------------ | ------------------------------------------------------------ |
| **Returns:** | **y_pred ：ndarray of shape (n_samples)**<br /> X中样本的标签 |

- property **predict_log_proba**

计算X中各样本的分类结果概率。

fit中的参数probability应该设置为 True

| Parameters | X：array-like of shape (n_samples, n_features)<br />    对于内核”percomputed“， 期望的X形状为（n_samples_test, n_samples_train） |
| :--------- | ------------------------------------------------------------ |
| Returns:   | **T**: ndarray of shape (n_samples, n_classes)<br />对于模型的每一个class，返回样本标签的可能值。 |

- score(X, y, sample_weight = None)

  对于给定的待预测数据和标签，返回平均准确率

  ‎在多标签分类中，这是子集精度，这是一个‎‎苛刻的指标‎‎因为您要求每个样本正确预测每个标签集。‎

| Parameters:  | X：array-like of shape （n_samples, n_features）<br />测试样本<br />y：array-like of shape （n_samples,） or (n_samples, n_outputs)<br />X的真实标签<br />sample_weight: array-like of shape (n_samples,), default  = None<br />Sample weights |
| ------------ | ------------------------------------------------------------ |
| **Returns**: | **score:float**<br />  Mean accuracy of `self.predict(X)` wrt. `y`. |

- set_params(**params)

- 

### 5、参数的选择（C、kernel）

##### 		5.1 C

​		使用更大的C，具有低偏差、高方差，更倾向于过拟合；使用较小的C，具有高偏差、低方差，更倾向于欠拟合。

##### 				5.1 liner kernel 

​		无核函数的SVM模型。

​		**样本数（m）很小，特征数（n）很大时**，就只想拟合一个线性的判定边界，而不去拟合一个非常复杂的非线性函数（因为没有足够的数据，可能会过拟合），可以不使用核函数，或者一种被叫做使用线性内核函数的等价物。

##### 				5.2 高斯核函数（rbf）

​		参数σ^2的选择。较大时，会生成一个较大的偏差，较低方差的分类器。较小时，会生成一个较大方差、较低误差的分类器。

​		**样本数（m）很大，特征数（m）较小时。**如图m=18，n=2 ，使用高斯核函数较好

![image-20210802203921280](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210802203921280.png)

##### Note：分类器的偏差和方差

​		偏差（距离远近）：描述的是预测值的期望与真实值之间的差距，偏差越大，越偏离真实数据。

​		方差（是否聚集）：预测值的方差，描述的是预测值的变化范围，离散程度，也就是离预测值期望值的距离，方差越大，数据的分布越分散。

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210802210026032.png" alt="image-20210802210026032" style="zoom:67%;" />

​		红色表示样本的真实值。

​		模型欠拟合时，偏差较大，模型过拟合时，方差较大。如下图所示。<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210802210829630.png" alt="image-20210802210829630"  />

- 上左图使用直线对数据进行拟合，直线不能很好地分割数据，预测值将有大量分错，测试模型偏差过大，欠拟合。
- 上右图模型过度拟合数据，将数据中的噪声点也学到，此时数据的轻微波动将会导致预测结果的波动，模型方差过大，过拟合。



# 二、KNN（K Near Neighbor）

### 	1、概念

- k个最近的邻居，即每个样本都可以用它最近的k个邻居来代表。
- 基本思想：一个样本与数据集中的k个样本最相似，如果这k个样本大都数属于某一个类别，那么这个样本也属于某一个类别。	

### 2、距离向量

闵氏距离定义：<img src="C:\Users\yyyyyyyyyyyy\AppData\Roaming\Typora\typora-user-images\image-20210726153908559.png" alt="image-20210726153908559" style="zoom: 50%;" />

当p=1时，为曼哈顿距离 <img src="C:\Users\yyyyyyyyyyyy\AppData\Roaming\Typora\typora-user-images\image-20210726154153554.png" alt="image-20210726154153554" style="zoom:50%;" />

当p=2时，为欧式距离 <img src="C:\Users\yyyyyyyyyyyy\AppData\Roaming\Typora\typora-user-images\image-20210726154118690.png" alt="image-20210726154118690" style="zoom:50%;" />

当p→∞时，为切比雪夫距离 *d*12=*m**a**x*(∣*x*1−*x*2∣,∣*y*1−*y*2∣)

### 3、K值选择

​        如果选用较小的K值，就相当于用较小的邻域中的训练实例进行预测，学习的**近似误差**会减小；缺点是学习的**估计误差**会增大，预测结果会对近邻的实例点成分敏感。如果邻近的实例点恰巧是噪声，预测就会出错。To sum up ，K值减小，模型变得复杂，容易过拟合。

​		如果选择较大的K值，相当于用较大邻域中的训练实例进行预测，优点是可以减少学习的估计误差，但**近似误差**会增大，就是对输入的实例预测不准确。To sum up ， K值增大，模型变得简单，容易欠拟合。

​		PS：近似误差：可以理解为对现有训练集的训练误差。估计误差：可以理解为对测试集的测试误差。

​		在应用中，K值一般取一个比较小的数值，通常采用交叉验证法来选取最优的K值。

### 4、sklearn官方文档

```
class sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)
```

- **n_neighbors:int,default = 5**

  Number of neighbors to use by default for kneighbors queries

- **weights: {'uniform', 'distance'} or callable, default = 'uniform'**

  weight function used in predictoin.

  uniform:每个邻居的权重相同

  distance：权重的大小与它们到样本的距离成反比

  [callable]: a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.

- **algorithm: {‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, default=’auto’**

  用来计算最近邻居的算法.

  ‘ball_tree’ 使用的是 BallTree

  ‘kd_tree’使用的是 KDTree

  ‘brute’使用的是 brute-force search

  'auto'会根据传递给fit函数的值，自动选择最佳的算法

- **leaf_size: int, default=30**

传递给BallTree或KDTree的叶子大小。影响了建立数据结构和查询的速度，以及需要的存储空间大小。

- **p：int, default=2**

Power parameter for the Minkowski metric.

p为闵氏距离的参数（具体见2、距离向量）。

p=1时，使用曼哈顿距离

p=2时，使用欧氏距离

- **metric：str or callable, default=’minkowski’**

使用的距离标准。默认为闵式距离（Minkowski）。If metric is “precomputed”, X is assumed to be a distance matrix and must be square during fit. X may be a [sparse graph](https://scikit-learn.org/stable/glossary.html#term-sparse-graph), in which case only “nonzero” elements may be considered neighbors.

- **metric_params: dic, default=None**

指标函数（metric function）的其他关键字参数

- **n_jobs: int, default=None**

查询时的并行任务数。None表示1，除非是在joblib parallel中读取的模型。-1表示使用所有的可用进程。

###### 1、kd树（k-dimensional树）：

​		使用准则：在k维情况下，数据点数目N应当远远大于
$$
2^k时，k-d树的最邻近搜索才可以很好地发挥其作用
$$
​		每个节点都为k维点的二叉树。所有非叶子节点可以视作用一个超平面把空间分割成两个半空间。kd树算法一般包括两个部分，一部分是kd树本身这种数据结构的建立，另一部分是在建立的kd树上进行最邻近查找的算法。

​		假设有6个二维数据点{（2,3），（5,4），（9,6），（4,7），（8,1），（7,2）}，数据点位于二维空间内（如图1中黑点所示）。k-d树算法就是要确定图1中这些分割空间的分割线（多维空间即为分割平面，一般为超平面）。<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210728203823232.png" alt="image-20210728203823232"  />

​		**构建kd树**：首先给出kd树每个节点中主要包含的数据结构。

| 域名      | 数据类型 | 描述                                                    |
| --------- | -------- | ------------------------------------------------------- |
| Node-data | 数据矢量 | 数据集中某个数据点，是n维矢量（这里也就是k维）          |
| Range     | 空间矢量 | 该节点所代表的空间范围                                  |
| split     | 整数     | 垂直于分割超平面的方向轴序号                            |
| Left      | k-d树    | 由位于该节点分割超平面左子空间内所有数据点所构成的k-d树 |
| Right     | k-d树    | 由位于该节点分割超平面右子空间内所有数据点所构成的k-d树 |
| parent    | k-d树    | 父节点                                                  |

​		以上实例的构建过程：数据维度只有二维，可以简单地给x，y两个方向轴编号为0，1，即split={0，1}

1. ​	确定split域首先该取的值。分别计算x，y方向上数据的方差得知x方向上的方差最大，所以spilt域值首先取0，也就是x轴方向；
2. 确定Node-data的域值，根据x轴方向的值2，5，9，4，8，7排序选出中值为7，所以Node-data = (7,2) 。该节点的分割超平面就是通过（7，2）并垂直于split=0（x轴）的直线 x = 7；
3. 确定左子空间和右子空间。分割超平面x = 7将整个空间分为两部分。x<=7的部分为左子空间，x>=7的部分为右子空间。
4. 递归，对左子空间和右子空间内的数据重复根节点的操作，将空间和数据集进一步细分。如此反复直到空间中只包含一个数据点。

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210728211118911.png" alt="image-20210728211118911" style="zoom: 80%;" />

**查找算法**：检索在kd树中与查询点距离最近的数据点。

​		在上例中，假设要查找的点为（2.1，3.1）。通过二叉搜索，顺着搜索路径最邻近的点近似点，叶子节点（2，3）计算其到查询点（2.1,3.1）的距离为0.1414，然后回溯到其父节点（5,4），并判断在该父节点的其他子节点空间中是否有距离查询点更近的数据点。以（2.1,3.1）为圆心，以0.1414为半径画圆，如图4所示。发现该圆并不和超平面y = 4交割，因此不用进入（5,4）节点右子空间中去搜索。

​		再回溯到（7,2），以（2.1,3.1）为圆心，以0.1414为半径的圆更不会与x = 7超平面交割，因此不用进入（7,2）右子空间进行查找。至此，搜索路径中的节点已经全部回溯完，结束整个搜索，返回最近邻点（2,3），最近距离为0.1414。

![image-20210728213645998](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210728213645998.png)

​		查找点（2，4.5）。同样先进行二叉查找，先从（7,2）查找到（5,4）节点，在进行查找时是由y = 4为分割超平面的，由于查找点为y值为4.5，因此进入右子空间查找到（4,7），形成搜索路径**<（7,2），（5,4），（4,7）>**，取（4,7）为当前最近邻点，计算其与目标查找点的距离为3.202。然后回溯到（5,4），计算其与查找点之间的距离为3.041。以（2，4.5）为圆心，以3.041为半径作圆，如图5所示。可见该圆和y = 4超平面交割，所以需要进入（5,4）左子空间进行查找。此时需将（2,3）节点加入搜索路径中得<（7,2），（2,3）>。回溯至（2,3）叶子节点，（2,3）距离（2,4.5）比（5,4）要近，所以最近邻点更新为（2，3），最近距离更新为1.5。回溯至（7,2），以（2,4.5）为圆心1.5为半径作圆，并不和x = 7分割超平面交割，如图6所示。至此，搜索路径回溯完。返回最近邻点（2,3），最近距离1.5 。

![image-20210728213735524](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210728213735524.png)

###### 2、ballTree

​		与kdTree的比较：	

- kdTree使用的是二叉树树形结构，沿着笛卡尔坐标进行划分，效果较低。

- ballTree在一系列嵌套的超球体上分割数据，就是说使用的是超球面而不是超矩形划分区域。虽然在构建数据结构的花费上大于kdTree，但是在高维甚至很高维的数据上都表现得很高效。

  **ballTree的构建:**

1. 把整个空间当作一个大簇。

2. 找到距离最远的两个点a和b，叫做**观测点**，以它们为种子。（选择一个距离当前圆心最远的观测点a，和距离a最远的观测点b）

3. 其余的簇内节点s分别计算与a和b的距离，离a近就归到a簇。

4. 确定圆心和半径（最小圆覆盖问题），得到的圆不能超过父类圆的范围，如果超出了会增加不少麻烦，因为超出部分必没有属于该簇的点，还容易在搜索时被干扰，增加搜索量。

5. 分别在上一步得到的两个圆内重复1-4步，直到只剩一个点，作为叶子节点存储下来。

   ![image-20210803152242224](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210803152242224.png)

   **balltree的搜索**

   给定一个ballTree里面的点g（x，y），求它的最近点

6. g肯定在一个小簇中，遍历小簇里的所有点，找到最近的那个点gmax，它虽然不是最近的点，但在同一个簇中，距离也不会太大，所以可以依照它为标准，寻找更近的点。gmax被称为**上界**

7. 设g到上界的距离为r，以g为圆心，r为半径画圆。ballTree中有节点在该圆内，则该节点与g的距离肯定更近。

8. 如何找到圆内距离更近的节点：肯定不能遍历整个ballTree，要不然ballTree没有意义。若距离更近的节点存在，那么这个点肯定在某个簇形成的圆中，那么它应该在步骤2所画的圆和已有簇的圆的相交区域中。
   - 我们根据步骤2画出的圆与某个簇F画出的圆相交，就看是否和它的两个子簇child1，child2。因为F的点都在子簇中
   - 如果与child1，child2都不相交，则与F也不会相交。
   - 如果与child1相交，与child不相交，则看child1里面的两个子簇grandChild1，grandChild2.
   - 如果与child1，child2都相交，则两个下面的子簇都看看
   - 直到我们发现了叶子节点。叶子节点是具体的点，没有半径和圆心。此时直接拿点出来与目标点计算距离。
   - 如果还没挖到叶子节点，就找不到相交的圆了，就说明这一枝不存在相交的点，放弃这一枝的搜索。

9. 不在ballTree里的点找最近点：自己确定一个上界

### 5、代码实现

**实现原理：对每个未知类别属性的数据集中的每个点依次执行以下操作：**

1. 计算已知类别数据集中的点与当前点之间的距离；
2. 按照距离递增次序排序
3. 选取与当前点距离最小的K个点
4. 确定前k个点所在类别的出现频率
5. 返回前k个点出现频率最高的类别作为当前点的预测分类

**使用sklearn封装好的库**：([sklearn.neighbors.KNeighborsClassifier — scikit-learn 0.24.2 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier))

使用KNN算法之前，我们要决定K的值是多少。要选出最优的K值，可以使用sklearn中的交叉验证方法。代码如下：

```
from sklearn.datasets import load_iris
from sklearn.model_selection  import cross_val_score
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier

#读取鸢尾花数据集
iris = load_iris()
x = iris.data			# 特征
y = iris.target			# 标签
k_range = range(1, 31)	# 
k_error = []			# 定义列表

#循环，取k=1到k=31，查看误差效果
for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    #cv参数决定数据集划分比例，这里是按照5:1划分训练集和测试集,并使用交叉验证方法(6折交叉验证)
    #返回的scores是6行1列的数组，表示交叉验证中每一轮的验证准确率
    scores = cross_val_score(knn, x, y, cv=6, scoring='accuracy') 
    k_error.append(1 - scores.mean())	#在列表末尾添加新的元素，
#画图，x轴为k值，y值为误差值
plt.plot(k_range, k_error)
plt.xlabel('Value of K for KNN')
plt.ylabel('Error')
plt.show()
```

结果：

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210728173730119.png" alt="image-20210728173730119" style="zoom:80%;" />

可以看到K取12的时候效果最好。在实际问题中，如果数据集比较大，K的取值可以缩小以减少训练时间。

选取K值后，运行KNN算法，具体代码如下：

```
import matplotlib.pyplot as plt
from numpy import *
from matplotlib.colors import ListedColormap
from sklearn import neighbors, datasets

n_neighbors = 11

# 导入一些要玩的数据
iris = datasets.load_iris()
x = iris.data[:, :2]  # 我们只采用前两个feature,方便画图在二维平面显示
y = iris.target


h = .02  # 网格中的步长

# 创建彩色的图
cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])
cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])


#weights是KNN模型中的一个参数，上述参数介绍中有介绍，这里绘制两种权重参数下KNN的效果图
for weights in ['uniform', 'distance']:
    # 创建了一个knn分类器的实例，并拟合数据。
    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)
    clf.fit(x, y)

    # 绘制决策边界。为此，我们将为每个分配一个颜色
    # 来绘制网格中的点 [x_min, x_max]x[y_min, y_max].
    x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1
    y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])

    # 将结果放入一个彩色图中
    Z = Z.reshape(xx.shape)
    plt.figure()
    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)

    # 绘制训练点
    plt.scatter(x[:, 0], x[:, 1], c=y, cmap=cmap_bold)
    plt.xlim(xx.min(), xx.max())
    plt.ylim(yy.min(), yy.max())
    plt.title("3-Class classification (k = %i, weights = '%s')"
              % (n_neighbors, weights))

plt.show()
```



# 三、CNN（卷积神经网络）

### 1、人工神经网络

##### 	1.1、神经元

​	    神经网络由大量的神经元相互连接而成。每个神经元接收线性组合的输入后，最开始只是简单的线性加权，后来给每个神经元加上了非线性的激活函数，从而进行非线性变换后输出。

​		每两个神经元之间的连接代表加权值，称之为权重（weight）。不同的权重和激活函数，会导致神经网络不同的输出。

神经网络的每个神经元：

​		      						<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210726162456816.png" alt="image-20210726162456816" style="zoom:80%;" />

 z = wx + b，其中：

- x1、x2表示输入向量；

- w1、w2表示权重，几个输入则意味着由几个权重。

- b为偏置量bias；

- g(z) 为激活函数；

- a为输出；

#####   1.2、激活函数

​		常用的非线性激活函数有sigmoid、tanh、relu等，前两者sigmoid、tanh比较常见于全连接层，后者relu常见于卷积层。

​		激活函数的作用：在生物意义上的神经元中，只有前面的树突传递的信号的加权和值**大于某一个特定的阈值**的时候，后面的神经元才会被激活。而卷积层中激活函数的意义就在于判定每个神经元的输出是否达到阈值。

###### 		1.2.1 sigmoid函数

​		表达式如下：![image-20210726163631890](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210726163631890.png)

​		图形图下：<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210726163654343.png" alt="image-20210726163654343" style="zoom:50%;" />

​		sigmoid的功能相当于把一个实数压缩到0到1之间，当z非常大时，g（z）趋近于1，当z非常小时，g（z）趋近于0

​		压缩至0到1的作用是：可以把激活函数看作一种“分类的概率”，如激活函数的输出为0.9，则表示该样本90%的概率为正样本。

###### 1.2.2 ReLu函数

​		表达式如下：

![image-20210802172510858](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210802172510858.png)

​		图型如下：

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210802172550566.png" alt="image-20210802172550566" style="zoom:50%;" />

##### 	1.3、神经网络

 将下图的这种单个神经元组织在一起，便形成了神经网络。

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210726164634868.png" alt="image-20210726164634868" style="zoom:80%;" />

下图是一个三层神经网路结构：

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210726164702727.png" alt="image-20210726164702727" style="zoom:80%;" />

从左到右依次为输入层、隐藏层、输出层。每一层可由单个或多个神经元组成，每一层的输出将会作为下一层的输入数据。

如下图中间的隐藏层，隐藏层的3个神经元a1、a2、a3各自接受来自多个不同权重的输入（因为有x1、x2、x3这三个输入，所以a1 a2

a3都会接受x1 x2 x3各自分别赋予的权重，即几个输入则几个权重），接着，a1、a2、a3又在自身各自不同权重的影响下成为输出层的输入，最终由输出层输出最终结果。

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210726170603481.png" alt="image-20210726170603481" style="zoom:50%;" /><img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210726170632563.png" alt="image-20210726170632563" style="zoom:50%;" />



### 	2、**卷积神经网络的层级结构**：

​	输入层、卷积层、激活函数、池化层、全连接层组成，即INPUT（输入层）-CONV（卷积层）-RELU（激活函	数）-POOL（池化层）-FC（全连接层）。

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210726170823389.png" alt="image-20210726170823389" style="zoom:50%;" />

​		最左边是数据输入层（图片-车），对数据做一些预处理，如去均值（把输入数据各个维度都中心化为0，避免数据过多偏差，影响训练效果）、归一化（把所有的数据都归一到同样的范围）。CNN只对训练集做“去均值”。

​		中间部分：

​		CONV：卷积计算层，线性乘积求和。卷积计算层是CNN的核心。

​		RELU：激活层，ReLU是激活函数的一种。

​		POOL：池化层，即取区域平均或最大（实际应用中发现取最大效果更好）。主要用于特征降维，压缩数据和参数数量，减小过拟合，提高模型容错率。

​		最右边是FC：全连接层。连接所有特征，将输出值送给分类器（如softmax分类器）进行分类，给出分类结果。

##### 代码示例：

```
# # 建立一个Sequential线性堆叠模型
model = Sequential()
model.add(Conv1D(filters=FILTERS,        #每个卷积核（过滤器）提取不一样的特征
                 kernel_size=KERNEL_SIZE,
                 input_shape=input_shape,
                 activation='relu'))
# 建立池化层
model.add(MaxPooling1D(pool_size=2))
# 建立平坦层
model.add(Flatten())
model.add(Dropout(DROPOUT_RATE))    #随机去掉一部分样本。
                            # 我们在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征
# 建立隐蔽层
model.add(Dense(128, activation='relu'))
model.add(Dropout(DROPOUT_RATE))
model.add(Dense(16, activation='softmax'))
print(model.summary())
```



### 3、卷积计算层

```
model.add(Conv1D(filters=FILTERS,        #每个卷积核（过滤器）提取不一样的特征
                 kernel_size=KERNEL_SIZE,
                 input_shape=input_shape,
                 activation='relu')
```

##### 	3.1卷积的概念

​		对图像（不同的数据窗口数据）和滤波矩阵（一组固定的权重：因为每个神经元的多个权重固定，所以又可以看做一个恒定的滤波器filter）做内积（逐个元素相乘再求和）的操作就是所谓的『卷积』操作，也是卷积神经网络的名字来源。

​		非严格意义上来讲，下图中红框框起来的部分便可以理解为一个滤波器，即带着一组固定权重的神经元。多个滤波器叠加便成了卷积层。

​		卷积层是用来进行特征提取，如下图所示：

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210802113333681.png" alt="image-20210802113333681" style="zoom:67%;" />

​		输入的图像是32* 32 *3 （其中3是深度）

​		卷积层是一个5* 5 *3的filter(滤波器)。**PS：滤波器的深度必须和输入图像的深度相同。**

​		通过一个filter与输入图像的卷积可以得到一个28 *28 *1的特征图，上图是用了两个filter得到了两个特征图；即是使用了多少个filter，就会得到多少个特征图。

​		32 * 32 * 3是如何变成28 * 28 * 1的

1.  32 -> 28 

   图像长32，filter长5，从左到右滑动，在图像没有加0的情况下，每滑动一次，计算一个结果。最后得到的结果为32-5+1=28.垂直方向上同理。

2.  3 -> 1.

   与卷积的计算有关。**图像深度和滤波器深度相同**。卷积的计算：图像的各层次与filter的各层次分别计算后得到的结果再相加，最终才得到特征图上的值。所以不管深度是多少，一个filter得到的特征图，深度都是1.有几个filter，特征图的深度就是几。

##### 3.2卷积的计算

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210802151849585.png" alt="image-20210802151849585" style="zoom:80%;" />

##### 3.3完整的卷积计算

​		在CNN中，滤波器filter（带着一组固定权重的神经元）对局部输入数据进行卷积计算。每计算完一个数据窗口内的局部数据后，数据窗口不断平移滑动，直到计算完所有数据。

​		**过程中相关的参数：**

1. 深度depth: 神经元个数，决定输出的depth厚度。同时代表滤波器的个数。

2. 步长： 数据窗口每次滑动多长，决定了滑动到边缘的步数。

3. 填充值 zero-padding: 在外围边缘补充若干圈0，方便从初始位置以步长为单位可以刚好滑到末尾位置（即方便总长能被步长整除）。

   一般有：

   F=3=> zero pad with 1

   F=5 => zero pad with 2

   F=7 => zero pad with 3

   边界宽度是一个经验值，加上zero pad这一项是为了使输入图像和卷积后的特征图具有相同的维度。

​		**举例：**

​		看下面卷积计算的一个图，可以看到：

​		两个神经元，即depth=2，意味着有两个滤波器。

​		数据窗口每次移动两个步长，取3*3的局部数据，即stride=2。

​		zero-padding = 1。

​		然后分别以两个滤波器filter为轴滑动数组进行卷积计算，得到两组不同的结果。

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210802153721000.png" alt="image-20210802153721000" style="zoom:80%;" />

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210802153737039.png" alt="image-20210802153737039" style="zoom:80%;" />

##### 3.3  Conv1D和Conv2D的区别

- Conv2D主要应用于数字图像处理，卷积核的尺寸是一个二维的元组，当然也可以传入整数，代表w==h，步长同理。

- Conv1D主要应用于文本序列，卷积核的尺寸是整数 l ，步长同理。

- 概括：Conv2D先横着扫再竖着扫，Conv1D只能竖着扫。



### 4、池化层

```
# 建立池化层
model.add(MaxPooling1D(pool_size=2))
```



```
tf.keras.layers.MaxPooling1D(
    pool_size=2, strides=None, padding="valid", data_format="channels_last", **kwargs
)
```

- **pool_size**: Integer, size of the max pooling window.
- **strides：**Integer，or None。pooling window 每一步移动的步长。
- **padding：**“valid”或者“same”。参考卷积层里面的zero-padding。valid表示不填充，same表示在输入的周围填充，使得池化层的输出维度与输入维度相同。
- **data_format:** 字符串类型，值为 channels_last(default)或者channels_first.`channels_last` corresponds to inputs with shape `(batch, steps, features)` while `channels_first` corresponds to inputs with shape `(batch, features, steps)`.

类似于压缩图片。如下图 max pool即取设定矩阵里最大的值作为输出数据：

![image-20210802172223240](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210802172223240.png)

### 5、平坦层

```
# 建立平坦层
model.add(Flatten())
model.add(Dropout(DROPOUT_RATE))    #随机去掉一部分样本。
                            # 我们在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征
```



```
tf.keras.layers.Flatten(data_format=None, **kwargs)
```

将输入展开。不影响batch size

Note：如果输入的形状为（batch，），即输入不包含特征轴，那么平坦层会增加一个额外的通道维度，输出的形状为（batch，1）。

**举例：**

```
>>> model = tf.keras.Sequential()
>>> model.add(tf.keras.layers.Conv2D(64, 3, 3, input_shape=(3, 32, 32)))
>>> model.output_shape
(None, 1, 10, 64)
```

```
>>> model.add(Flatten())
>>> model.output_shape
(None, 640)
```

### 6、全连接层[Dense layer (keras.io)](https://keras.io/api/layers/core_layers/dense/)

##### 6.1 API

```
# 建立全连接层
model.add(Dense(128, activation='relu'))
model.add(Dropout(DROPOUT_RATE))
model.add(Dense(16, activation='softmax'))
```

```
tf.keras.layers.Dense(
    units,
    activation=None,
    use_bias=True,
    kernel_initializer="glorot_uniform",
    bias_initializer="zeros",
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
```

- **units**： 该层的神经单元节点数。









##### 6.2 全连接层的结构

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210802212455714.png" alt="image-20210802212455714" style="zoom:80%;" />

**全连接层是由许多神经元组成的 （1*4096）的平铺结构**

​		如何将上图3 * 3 * 5的输入，转换成1 * 4096 的形式？可以理解为在中间做了卷积（参考卷积计算层）：<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210802212913142.png" alt="image-20210802212913142" style="zoom:80%;" />

​		用一个3×3×5的filter取卷积激活函数的输出，得到的结果就是全连接层一个神经元的输出。

​		因为我们由4096各个神经元，所以要用4096个3×3×5的filter去卷积激活函数的输出。

##### 6.3 全连接层的作用

​		把分布式特征representation映射到样本标记空间。通俗来说，**就是把特征representation整合到一起，输出为一个值。可以大大减少特征位置对分类带来的影响。**

​		举个简单的例子：<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210803094204827.png" alt="image-20210803094204827" style="zoom:67%;" />

​		猫在不同的猫在不同的位置，输出的feature值相同，但是位置不同。

​		对于电脑来说，特征值相同，但是特征值位置不同，那分类结果也可能不一样。

​		**而这时全连接层filter的作用就相当于把feature map 整合成一个值（通过这个值的大小来判断样本是否为猫）。不管猫在哪，只要找到这只猫就行。**

​		**因为空间结构特性被忽略了，所以全连接层不适合用于在方位上找Pattern的任务，比如segmentation**

##### 6.4 多层全连接层

​		大部分全连接层有两层以上。是为了更好地解决非线性问题。

​		我们现在的任务是去区别一图片是不是猫

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210803100106898.png" alt="image-20210803100106898" style="zoom:50%;" />

​		假设这个神经网络模型已经训练完了。全连接层已经知道

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210803100206384.png" alt="image-20210803100206384" style="zoom:50%;" />

​		当我们获得以上特征，就可以判断这张图片是猫了。

​		因为全连接层的作用主要就是实现分类（Classification）

​		从下图，我们可以看出![image-20210803100337732](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210803100337732.png)

​		**红色的神经元表示这个特征被找到了（激活了），同一层的其他神经元，要么猫的特征不明显，要么没找到**当我们把这些找到的特征组合在一起，发现最符合要求的是猫。

​		而左边那层的作用就是**对子特征分类，也就是对猫头，猫尾巴，猫腿等进行分类。**

![image-20210803100602755](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210803100602755.png)

​		找到猫头的特征，比如眼睛，耳朵。

![image-20210803100634241](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210803100634241.png)

​		**当我们找到这些特征，神经元就被激活了（上图红色圆圈）**





# 四、LSTM

### 1、背景

 		人类可以根据上下文思考单词，不会每次都扔掉所有东西，然后再从头开始思考。思考具有持久性。传统的神经网络不能做到这一点，因为其信息不是持续存在的。循环神经网络解决了这个问题。

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210726193830507.png" alt="image-20210726193830507" style="zoom:50%;" />



​		在上图中，一块神经网络A查看一些输入Xt并输出一个值ht。循环允许网络从一个步骤传递到下一个步骤。

​		可以将循环神经网络视为同一网络的多个副本，每个副本都将消息传递给后继者。![image-20210726194137919](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210726194137919.png)

​		经典的循环神经RNN可以将先前信息连接到当前任务，例如使用先前的视频帧可能有助于对当前帧的理解。下图为RNN连接过去信息的图示：

![image-20210726195031199](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210726195031199.png)

​		RNN的缺陷为：当相关信息与所需信息之间的距离很大时，RNN难以连接过去的信息（理论上可行，但实现起来十分困难）。下图为RNN由于过大的差距，难以使用过去信息的图示：![image-20210726195131734](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210726195131734.png)



​		而LSTM（长短期内存网络），作为一种特殊的RNN，能够学习长期依赖性。

### 2、原理

​			在标准RNN中，该重复模块将具有非常简单的结构，例如单个tanh层。

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210726200921554.png" alt="image-20210726200921554" style="zoom:67%;" />

​		LSTM也具有这种类似链的结构，但重复模块具有不同的结构。有四个，而不是一个神经网络层，以一种非常特殊的方式进行交互。

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210726201558873.png" alt="image-20210726201558873" style="zoom:67%;" />

​		LSTM的关键是单元状态，水平贯穿图的顶部。

# 五、DecisionTree

### 1、步骤

特征选择、决策树的生成、决策树的修剪

# 六、朴素贝叶斯（NB）

### 1、原理

在贝叶斯算法的基础上进行了相应的简化，即假定给定目标值时属性之间相互独立条件。即没有哪个属性变量对于决策结果来说占有者较大的比重，也没有哪个属性变量对于决策结果占有着较小的比重。

##### 1.1思路：

1、根据贝叶斯公式：P（输出|输入）=P（输入|输出）*P（输出）/P（输入）

2、P（输入）=历史数据中，某个输入占所有样本的比例；

3、P（输出）=历史数据中，某个输出占所有样本的比例；

4、P（输入|输出）=历史数据中，某个输入，在某个输出的数量占所有样本的比例，例如：30岁，男性，中午吃面条，其中【30岁，男性就是输入】，【中午吃面条】就是输出。

##### 1.2贝叶斯公式

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210805201032437.png" alt="image-20210805201032437" style="zoom: 67%;" />

### 2、不同数据分布的模型

[API Reference — scikit-learn 0.24.2 documentation](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.naive_bayes)

##### 2.1 **BernoulliN**B

like MultinomialNB, this classifier is suitable for **discrete data**. The difference is that while MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolean features.

```
`sklearn.naive_bayes.``BernoulliNB`(***, *alpha=1.0*, *binarize=0.0*, *fit_prior=True*, *class_prior=None*)
```

##### 2.2 CategoricalNB

对于分类数据的朴素贝叶斯分类器

```
sklearn.naive_bayes.CategoricalNB(*, alpha=1.0, fit_prior=True, class_prior=None, min_categories=None)
```

The categorical Naive Bayes classifier is suitable for classification with discrete features that are categorically distributed. The categories of each feature are drawn from a categorical distribution.

##### 2.3 ComplementNB

The Complement Naive Bayes classifier was designed to correct the “severe assumptions” made by the standard Multinomial Naive Bayes classifier. It is particularly suited for imbalanced data sets.

##### 2.4 GaussianNB

**高斯朴素贝叶斯**。这个分类器假设每个标签的数据都服从简单的高斯分布。特征变量是连续变量，符合高斯分布，比如说人的身高、物体的长度。

##### 2.5 MultinomialNB

**多项式朴素贝叶斯**

假设特征是由一个简单多项式分布生成的。

多项式分布可以描述各种类型样本出现次数的概率，因此多项式朴素贝叶斯非常适合用于描述出现次数或者出现次数比例的特征。

多项式朴素贝叶斯通常用于文本分类，其特征都是指待分类文本的单词出现次数或者频率。

### 3、高斯

# 七、二次判别分析（QDA）

### 1、介绍

​		判别分析包括可用于分类和降维的方法。线性判别分析（LDA）特别受欢迎，因为它既是分类器又是降维技术。二次判别分析（QDA）是LDA的变体，允许数据的非线性分离。最后，正则化判别分析（RDA）是LDA和QDA之间的折衷。

​		与线性判别分析类似，二次判别分析是另外一种线性判别分析算法，二者拥有类似的算法特征，**但QDA不能用作降维技术。**当不同分类样本的协方差矩阵相同时，使用线性判别分析；当不同分类样本的协方差矩阵不同时，则应该使用二次判别。

​		下图显示了在固定协方差矩阵以及不同协方差矩阵下LDA和QDA的表现差异：

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210805205406636.png" alt="image-20210805205406636" style="zoom:80%;" />

​		由图中可以看出，在固定协方差矩阵下，LDA和QDA是没有分类结果差异的（上面两张图）；但在不同的协方差矩阵下，LDA和QDA的分类边界明显存在差异，而且LDA已经不能准确的划分数据（下面两张图）。

​		**Note：**协方差矩阵。

​		协方差矩阵就是用来描述维度间关系的一个指标。

​		协方差就是用来描述维度间关系的一个指标。它的定义为：任意两个随机变量X和Y的协方差，记为Cov(X,Y)，定义为*：*

​		Cov(X,Y)=E{[X-E(X)] [Y-E(Y)]}

​		其中E(X)、E(Y)反映分量X、Y各自的均值。它反映的是任意**两个**随机变量（或者是任意两个维度） 间的关系：

- 当X取值不断增大时，Y也不断增大，此时Cov(X,Y)>0
- 当X取值不断减小时，Y也不断减小，此时Cov(X,Y)>0
- 当X取值不断增大时，Y却不断减小，此时Cov(X,Y)<0
- 当X取值不断减小时，Y却不断增大，此时Cov(X,Y)<0

总结X和Y之间的规律就是，当两个随机变量倾向于沿着相同趋势变化时为正协方差，反之则为负协方差。

​		协方差只能显示2个维度的关系，把三个矩阵同时显示出来，需要用到矩阵，即协方差矩阵。

# 八、高斯过程（GP）

### 1、整体说说

**GP的一个sample不再是一个普通的点，而是一个函数。**

为了理解高斯过程，我们就首先需要了解如下预备知识，即：高斯分布（函数）、随机过程、以及贝叶斯概率等。明白了这些预备知识之后才能顺利进入高斯过程，了解高斯过程本质及其高斯过程描述方法。人们又将高斯过程与贝叶斯概率有机结合在一起，构造了强大的数学方法（或称模型），为人类提供解决日常生活和工作的问题。特别是在人工智能领域更是意义非凡。为什么呢？

1. 高斯过程模型属于无参数模型，相对解决的问题复杂度及与其它算法比较减少了算法计算量。
2. 高斯模型可以解决高维空间（实际上是无限维）的数学问题，可以面对负杂的数学问题。
3. 结合贝叶斯概率算法，可以实现通过先验概率，推导未知后验输入变量的后验概率。由果推因的概率。
4. 高斯过程观测变量空间是连续域，时间或空间。
5. 高斯过程观测变量空间是实数域的时候，我们就可以进行回归而实现预测。
6. 高斯过程观测变量空间是整数域的时候（观测点是离散的），我们就可以进行分类。结合贝叶斯算法甚至可以实现单类分类学习（训练），面对小样本就可以实现半监督学习而后完成分类。面对异常检测领域很有用，降低打标签成本（小样本且单类即可训练模型）。

##### 1.1高斯分布（高斯函数）

![image-20210806221418307](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210806221418307.png)

​		N表示Normal，即正态分布（高斯分布就是正态分布），μ表示均值，σ平方表示方差，一维高斯分布函数图形是一个钟形曲线，决定了x取不同值的概率。μ体现了钟形曲线对称轴的位置。σ表示标准差，体现了“钟”的宽度。

​		例子：

![image-20210806221837694](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210806221837694.png)



##### 1.2 应用（异常检测）

1. 欺诈检测

   对不同的用户行为计算特征变量。建立模型来表现用户各种行为的可能性对应的特征向量出现的概率。根据权重和特征计算p（x），若结果小于一定阈值，则认为是异常用户，

2. 飞机引擎的异常判断

​	<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210806213708191.png" alt="image-20210806213708191" style="zoom:80%;" />

​		红点表示通过模型训练和检测已经判定为正常引擎的样本。绿点表示现在需要判断的样本。中间的绿点于红点接近，可以判定为正常引擎样本。右下角的绿点远离正常引擎样本群，判定为异常样本（或不能判定为正常样本，需要进一步分析引擎是否正常）。

 3. 数据中心的计算机监控

    ![image-20210806214901027](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210806214901027.png)

### 2、算法

##### 1.3 参数估计

​		给出样本集，假设其符合高斯分布，计算出μ和σ。计算所有样本的平均值和标准差，就可得到参数

##### 2.3 建模

​		![image-20210807094349791](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210807094349791.png)

​		已有正常样本用图中红点表示。假设特征x_1,X_2……X_n均满足高斯分布，用不同的高斯分布函数分别表示x_1,x_2……x_n，再相乘得到p（x）

​		**举例：**

![image-20210807095046245](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210807095046245.png)

​		特征有两类。分别用不同参数的高斯分布函数表示，计算平均值和方差可得，u1=5，σ²=4；u=3，σ²=1
$$
p(x)=p(x1;μ1,(σ1)²)p(x2;μ2,(σ2)²)
$$
​		即二维高斯分布函数。现有两个样本点x1_test,x2_test,设ε=0.02，即p(x)＞0.02时为正常样本。计算可知p(x1_test)=0.0426＞ε，判定为正常样本；p(x2_test)=0.0021<ε，判定为异常样本。

​		可以对判定方法进行改进。

![image-20210807100915364](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210807100915364.png)![image-20210807100934248](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210807100934248.png)	    

​		

​		直接划分一个范围，范围内的值都具有较高的概率，认为是正常样本。范围外的值概率都较低，认为是异常样本。

##### 2.4 异常检测算法

![image-20210807102949627](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210807102949627.png)

##### 		2.5 异常检测算法与监督学习算法的对比

![image-20210807104732282](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210807104732282.png)



​		异常检测适用情况：

- 正样本（异常样本）很少，负样本（正常样本）很多，可以用负样本来拟合高斯曲线。

- 有很多不同种类的异常，算法很难从正样本集学习到异常的所有情况，未来出现的异常可能与已知的异常完全不同。

- eg: 欺骗检测（大量用户中的少量用户）；引擎制造问题；数据中心的计算集群。

  监督学习适用情况：

- 正样本集和负样本集都很大。

- 足够的正样本数来得到可以检测所有异常情况的算法。之后可能的异常与已知的一样十分相似。

- eg：垃圾邮件；天气预报；癌症分类

##### 2.6 不是高斯分布的数据

![image-20210807111141849](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210807111141849.png)

​		画出数据直方图，通过log变换，或者加指数等，使其更接近高斯分布。也可以跳这一步。直接用高斯过程处理数据。

##### 2.7 异常检测的算法评估和建立新的特征

![image-20210807112224874](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20210807112224874.png)

左图中的异常样本混在正常样本之间，这启发我们增加一个新的特征。如右图所示，引入特征x2后，异常样本的p(x)值很小，模型表现得很好。

### 2、多分类

当用于多分类时，采取的方式与支持向量机多分类方式一致，即"one VS rest"和"one VS one"。注意，采用"one VS one"方式时，n个类的多分类问题的核函数有<img src="C:\Users\yyyyyyyyyyyy\AppData\Roaming\Typora\typora-user-images\image-20210806111510593.png" alt="image-20210806111510593" style="zoom:50%;" />个

