# Backbone与Detection head

https://zhuanlan.zhihu.com/p/93451942

# 一、单级式目标检测方法

https://blog.csdn.net/qq_42722197/article/details/120329972

目标检测包含两大类方法——要么是在网格上进行固定数量的预测（单级式）；要么是先使用一个提议网络寻找目标，然后再使用另一个网络来微调这些提议并输出最终预测结果（两级式）。

## 1、基于网格的检测

用于提取原始图像丰富特征的卷积神经网络作为骨干网络。通常以图像分类器的形式进行预训练，原因是图像分类的数据成本更低（只需要单个标签，不用为每张图片标注边界框）。

![cf9a242ce0bde5dc3ca7d011c038adce.png](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/cf9a242ce0bde5dc3ca7d011c038adce.jpeg)

1. 以图像分类器的形式预训练骨干架构

2. **获得特征图集合**：移除网络最后几层，以便我们的骨干网络能输出堆叠的特征图集合。==特征图集合以更低的空间分辨率描述原图像，但是有着更高的特征（通道）分辨率==。在下面的示例中，我们对我们的观察有一个 7x7x512 的表示。这 512 个特征图中的每一个都描述了原图像的不同特性。<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/c355eaca01aa7ed7d616a9b949ecc3f3.jpeg" alt="c355eaca01aa7ed7d616a9b949ecc3f3.png" style="zoom: 80%;" />

3. **了解每个网格单元相对于原图像所代表的内容：**将这512个7*7网格关联回原输出。![f268aed99947c5f63100cc07a326f0fd.png](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/f268aed99947c5f63100cc07a326f0fd.jpeg)

4. **确定负责检测目标的网格单元**：包含边界框标注中心点（==是否为ground truth==）的网格单元，“负责”检测该特定目标![7437734852ee27f6667c9fbe4434da45.png](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/7437734852ee27f6667c9fbe4434da45.jpeg)

5. **得到4中的网格单元的激活：**添加另外一个卷积层并学习结合了所有512个特征图背景的==核参数==，得到一个对应于包含目标的网格单元的激活。![6f8ffdcd0311fa8227432559b1bdd2b3.png](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/6f8ffdcd0311fa8227432559b1bdd2b3.jpeg)

6. **多目标检测时包含多个激活**![bf5a1284b1a6ddadb3ffaa207ae7ae2d.png](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/bf5a1284b1a6ddadb3ffaa207ae7ae2d.jpeg)

7. **完整描述被检测出的目标：**不能使用单个激活就充分描述每个目标，为了完整描述被检测出的目标，还需要

   - 一个网格单元包含一个目标的可能（pobj）
   - 该目标属于哪个类别（c1，c2,...,cC）
   - 四个边界框描述量，描述标注框的x坐标，y坐标，宽度和高度（tx，ty，tw，th）==生成的==

   为上述每一个属性都学习一个卷积滤波器，就有5+C个输出通道来描述**每个网格单元“负责”的单个边界框**![46f2ce43f670561d28b6cd00d31bae53.png](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/46f2ce43f670561d28b6cd00d31bae53.jpeg)下图展示7*7网格应用5+C个卷积过滤器的完整输出。![2147959fa1a82e34324dab9065c67144.png](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/2147959fa1a82e34324dab9065c67144.jpeg)

8. **为每个网格单元位置预测B个边界框**：因为图像可能有多个目标都由同一网格单元”负责“，每个网格单元用B(5+C)个过滤器描述，这样就能为每个网格单元预测B个边界框。![de3d7fe57cacabf5e4c259e867175ea0.png](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/de3d7fe57cacabf5e4c259e867175ea0.jpeg)下图为B(5+C)个滤波器的完整卷积输出，模型总能为给定图像输出B个N*N预测，我们可以过滤预测，将pobj超过某个阈值的边界框作为最终结果。![d364c93f57527d1f092a0bcd89605143.png](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/d364c93f57527d1f092a0bcd89605143.jpeg)

9. 

## 2、YOLO

## 3、SSD

# 二、ResNet

https://blog.csdn.net/qq_45649076/article/details/120494328

## 1、ResNet 网络的亮点

- 超深的网络结构（超过1000层）
- 提出residual（残差结构）模块
- ==使用Batch Normalizatoin 加速训练（丢弃dropout）==

## 2、为什么采用residual

在ResNet提出之前，所有的神经网络都是由卷积层和池化层叠加组成，人们认为卷积层和池化层的层数越多，获取到的图片特征信息越全，学习效果越好，但实际中随着层数加深学习效果并没有变好，而是出现了**两种问题**：

1. **梯度问题**

   - **梯度消失**：若每一层的==误差梯度==小于1，==反向传播==时，网络越深，梯度越趋近于0

   - **梯度爆炸**：若每一层的误差梯度大于1，反向传播时，网络越深，梯度越来越大

2. **退化问题**：随着层数的增加，预测效果越来越差。![](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAcXFfNDU2NDkwNzY=,size_20,color_FFFFFF,t_70,g_se,x_16.png)

**问题的解决：**

1. **梯度消失或者梯度爆炸问题**

   - 数据预处理
   - 在网络中使用==BN（Batch Normalizaton）==

2. **退化问题**：人为地让神经网络某些层（==怎么选择哪些层来执行该操作==）跳过下一层神经元的连接，隔层相连，弱化每层之间的强联系。这种神经网络被称为**残差网络（ResNets）**。

   下图是使用residual结构的卷积网络，可以看到随着网络的不断加深，效果反而变得更好了。（虚线：train error；实线：test error）<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAcXFfNDU2NDkwNzY=,size_20,color_FFFFFF,t_70,g_se,x_16-1668415921319-23.png" alt="在这里插入图片描述" style="zoom: 67%;" />

## 3、residual 结构

采用shortcut的连接方式，让矩阵隔层相加。注意：F（x）和x形状要相同<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAcXFfNDU2NDkwNzY=,size_20,color_FFFFFF,t_70,g_se,x_16.png" alt="在这里插入图片描述" style="zoom:50%;" />

