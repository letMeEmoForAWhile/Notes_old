# 零、Questions&Concept&参考资料

## Questions

##### 1、特征关键点为什么不需要右边相机的垂直坐标

假设立体图像经过校正，则可以有效地完成此搜索，这意味着外极线（连接两张图像中相应点的线）是水平的。因此右相机的垂直坐标与左相机相同。

##### 2、选取关键点的策略是什么

关键因素是根据亮度选取角点，具体见Concept中的ORB特征

##### 3、使用关键帧的好处

场景不变时，不插入新的关键帧，不会重复建图，比较智能

##### 4、ORB-SLAM2和ORB-SLAM的区别在哪

- 使用近远点
- 增加了双目和RGB-D
- 因为一帧就有深度信息，所以初始化更快

## Concept

##### 1、重投影误差

[一文读懂重投影误差_少杰很帅的博客-CSDN博客](https://blog.csdn.net/weixin_49804978/article/details/121922128)

指的真实三维空间点在图像平面上的投影（也就是图像上的像素点）和重投影（其实是用我们的计算值得到的虚拟的像素点）的差值。

##### 2、BA

Bundle Adjustment，光束法平差。

##### 3、convisibility graph，共视图

<img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20230709170246609.png" alt="image-20230709170246609" style="zoom:50%;" />

共视图的含义即是**与当前关键帧有共同观测**的关键帧所组成的图。

- 无向加权图
- 如果两个关键帧之间满足一定的共视关系(至少有15个共同观测到的地图点),他们就连成一条边，边的权重就是共同观测到的地图点(共视地图点)的数目。

##### 4、ORB特征

[ORB特征_ros漫步的博客-CSDN博客](https://blog.csdn.net/qq_34493401/article/details/128371741)

Oriented FAST and Rotated BRIEF，最大的优点是提取速度快。

由**关键点**和**描述子**两部分组成。

- 关键点Oriented Fast：是一种改进的FAST角点。

  - FAST角点的主要思想：如果一个像素与领域的像素差别较大(过亮或者过暗)，那么它更可能是角点，速度非常快。检测过程如下：

    - 在图像中选取像素p，假设它的亮度为$I_p$
    - 设置一个阈值T(一般设为$I_p$的20%)
    - 以像素p为中心，选取半径为3的圆上的16个像素点。
    - 若选取的圆上由连续的N个点亮度大于$I_p+T$或者小于$I_p-T$，那么像素p就是特征点。
    - 循环上述步骤，对每一个像素执行相同的操作。

  - 关键点主要思想：

    - Fast特征点的主要缺点是不具有方向信息，并且有尺度问题。<!--远处看是角点的地方，近处看可能就不是角点了-->因此ORB添加了尺度和旋转的描述。

    - 尺度不变性：构建特征金字塔，对原始图像进行逐层缩放，得到各种尺度下的图像，缩小后的图像可以看成是从更远的地方看到的图像。在金字塔的每一层检测角点。

    - 特征旋转不变性：由灰度质心法实现。计算灰度质心Q，领域中心p到Q的方向就是特征点的方向。计算描述子的时候，在同样的坐标轴上计算。

      ![image-20230709163824282](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20230709163824282.png)

- 描述子BRIEF，是一种速度极快的二进制描述子。

  - 描述向量由许多个0和1组成，编码了关键点附近两个随机像素的亮度大小关系：领域中的像素q比像素p亮度更大，则取值为1，反之取0
  - 按高斯分布依次挑选256个这样的点对，最终得到一个256维的向量。


##### 5、关键帧

一个帧能代表周围很多帧。

##### 6、近点和远点

深度小于40倍双目或RGB-D相机基线距离的点称为近点，反之为远点。

##### 7、特征匹配

[SLAM之图像特征提取与匹配_slam特征匹配_W_Tortoise的博客-CSDN博客](https://blog.csdn.net/learning_tortosie/article/details/79888749)

特征匹配解决的问题是SLAM中的数据关联问题，即当前看到的路标和之前看到的路标之间的对应关系。

所有匹配点对：

![img](https://img-blog.csdn.net/20180413184412745?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xlYXJuaW5nX3RvcnRvc2ll/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

优化后的匹配点对：

![img](https://img-blog.csdn.net/20180413184513886?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xlYXJuaW5nX3RvcnRvc2ll/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

## 参考资料

[一步步复现ORBSLAM2 - 随笔分类 - 小C酱油兵 - 博客园 (cnblogs.com)](https://www.cnblogs.com/yepeichu/category/1356379.html)

# 一、系统架构

![image-20230617163454947](C:\Users\yyyyyyyyyyyy\Desktop\image-20230617163454947.png)

系统有三个并行线程：

- tracking：通过寻找与局部地图匹配的特征来定位每一帧的摄像机，并使用仅运动(motion-only)的BA==最小化重投影误差==。

  - 提取ORB特征

  - 第一阶段的跟踪：参考关键帧跟踪、恒速模型跟踪、重定位跟踪，得到粗略的相机位姿

  - 第二阶段的跟踪：局部地图跟踪，利用了当前帧的两级共视关键帧的信息，得到更加精确的位姿。具体来说，对当前帧的两级共视关键帧的所有地图点投影到当前帧进行匹配，对匹配结果做BA优化。

    <img src="https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20230709170246609.png" alt="image-20230709170246609" style="zoom:50%;" />

  - 决定是否产生新的关键帧：

- local mapping：针对新建关键帧的线程，管理并且优化局部地图，执行本地BA。

  - 插入关键帧
  - 剔除地图点
  - 生成地图点
  - 局部BA优化：==既优化相机位姿，又优化三维点。==
  - 剔除冗余关键帧

- loop closing：闭环检测，检测大的循环，通过执行位姿图优化纠正累积漂移。

  - 该线程在位姿图优化后启动第四个线程，执行全BA，计算最优结构和运动解。

位置识别模块：

- 使用DBoW2识别模块
- 用于在跟踪失败(比如遮挡)或者已经映射的场景中重新初始化的情况下的重新定位，以及进行闭环检测。

## 1、单目相机、近立体相机和远立体相机的关键特征

- ORB-SLAM2是基于特征的方法，如图Figure.2b所示,对输入进行预处理，提取显著关键点的特征。
- 输入图像在提取特征之后被丢弃，后续整个系统基于特征进行操作。

### 1.1 立体相机关键特征

立体相机关键点被定义为三个坐标：$X_s=(u_L,v_L,u_R)$

- $(u_L,v_L)$代表左图像的坐标点。

- $u_R$表示右侧图像的水平坐标。

- 对于左边的每个特征，都会在右边的图像中进行搜索以找到匹配的特征。

- 关键点在右相机的坐标与目标深度存在对应关系：

  - $u_R=u_L-\frac{f_x b}{d}$

  - $f_x$是水平焦距
  - b是两台摄像机之间的基线距离
  - d为目标特征点的深度
  - 通过这种映射，从双目相机提取的特征点和RBG-D的输入会被以相同的方式处理。



近立体和远立体

。。。。。。

### 1.2 单目相机特征点

$X_m = (u_L,v_L)$

当立体相机无法找到右相机匹配点或者RGB-D拥有错误的深度值。

## 2、系统引导

使用立体或ORB-D相机的主要好处：

- 仅从一帧获取深度信息，不需要像单目相机一样从运动初始化中获得特定结构。

## 3、单目和立体相机约束的光束法平差(Bundle Adjustment,BA)

三种BA：

- motion-only BA，仅运动BA，优化跟踪线程中的相机姿态
- local BA，局部BA，优化局部地图线程中关键帧和点的局部(local, 本地)窗口。
- full BA，完整BA，在执行完闭环检测之后优化所有的关键帧和点。

### 3.1、motion-only BA

优化相机姿态，包括相机的角度$R∈SO(3)$和位置$t∈\mathbb{R}^3$(即相机在世界坐标系下的位姿)。

- 最小化：真实世界3D点坐标$X^i∈\mathbb{R}^3$和关键点$x^i_{(·)}∈\mathbb{R}^2$的重投影误差。
  - ${R,t} =  \mathop{argmin}\limits_{R,t}  \mathop{\sum}\limits_{i∈\mathcal{X}} ρ(\left\|\ x^i_{(·)} - \pi_{(·)} (RX^i + t) \right\|^2_\sum )$

### 3.2、local BA

优化一组共视关键帧$\mathcal{K}_L$和这些关键帧中的所有点$\mathcal{P}_L$。

### 3.3、full BA

是局部BA的特殊情况，除了原点关键帧(origin keyframe)被固定以消除==量规自由==外，地图中的所有关键帧和点都被优化。

## 4、闭环检测

闭环检测的两个步骤

- 首先对闭环进行检测和验证。
- 其次对闭环进行矫正，优化位姿图。

## 5、关键帧插入

遵循ORB-SLAM的策略，ORB-SLAM2也经常插入关键帧，然后剔除冗余帧。

插入新关键帧的条件：

- 如果跟踪的近点的数量下降到一定阈值，并且帧可以至少创建一定数量的新的近点。

![image-20230709110950835](https://raw.githubusercontent.com/letMeEmoForAWhile/typoraImage/main/img/image-20230709110950835.png)

# 二、实验

# 三、不足之处

相比于直接法SLAM，特征提取部分比较耗时，运行速度没有直接法快。

相比于直接法SLAM，在弱纹理、重复纹理、图像模糊的场景下容易跟踪丢失。

产生的定位地图比较稀疏，应用有限。

